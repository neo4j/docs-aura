= Using the Apache Spark Connector
:product: Aura

NOTE: This example uses Java 11. Spark runs on Java 8 or 11.

== Setup

[NOTE]
====
TODO: Mention version of Spark and Scala
====

. Download the Spark Neo4j Connector from the https://github.com/neo4j-contrib/neo4j-spark-connector/releases[GitHub release^] page.
. Download Spark from the https://spark.apache.org/downloads.html[Download^] page (latest version, for example 3.3.0, pre-built for Apache Hadoop 3.3 and later).
. Decompress the downloaded file and launch the Spark shell as follows:
+
[source, shell]
----
$ spark-3.3.0-bin-hadoop3/bin/spark-shell --jars neo4j-connector-apache-spark_2.12-4.1.3_for_spark_3.jar
----

The code can be copy-pasted to the shell by activating the `paste` mode with the `:paste` command.

== Code

[source, scala]
----
import org.apache.spark.sql.{SaveMode, SparkSession}

val spark = SparkSession.builder().getOrCreate()

// Replace with the actual connection URI and credentials
val url = "neo4j+s://xxxxxxxx.databases.neo4j.io"
val username = "neo4j"
val password = ""
----

Writing to Neo4j:

[source, scala]
----
case class Person(name: String, surname: String, age: Int)

// Create example DataSource
val ds = Seq(
    Person("John", "Doe", 42),
    Person("Jane", "Doe", 40)
).toDS()

// Write to Neo4j
ds.write.format("org.neo4j.spark.DataSource")
    .mode(SaveMode.Overwrite)
    .option("url", url)
    .option("authentication.basic.username", username)
    .option("authentication.basic.password", password)
    .option("labels", ":Person")
    .option("node.keys", "name,surname")
    .save()
----

The written data can be checked with Neo4j Browser.

Reading from Neo4j:

[source, scala]
----
// Read from Neo4j
val data = spark.read.format("org.neo4j.spark.DataSource")
    .option("url", url)
    .option("authentication.basic.username", username)
    .option("authentication.basic.password", password)
    .option("labels", "Person")
    .load()

data.show()
----

Further information on the Neo4j Spark Connector https://neo4j.com/docs/spark/current/quickstart/[quickstart].